---
title: "Data Wrangling Lecture"
author: "Kaleb J. Frierson"
date: "2024-09-17"
output: 
  github_document: 
    toc: TRUE
---

# Notes

Today is data wrangling lecture. 

Tibbles are data frames, slightly different. Much better. Intended to solve problems that have emerged with data frames. Faster, more memory efficient, force you to do best practices. By default, anything that you import using tidyverse code will be a tibble. 

So what is a tibble? 

80/20 rule: 80% of import cases only take 20% of your time. 20% however will take like 80% of your time. 

Need to learn readr package, haven, readxl 

Readr is great for csv files and is common way to import. Readxl is great for excel spreadsheets. Haven is great for bringing data from other packages. 

Should be thoughtful about your data. Know what it should look like. See things that might be wrong, and why are they wrong? Something should be a number but it isn't, why is that the case? 

When you are doing data wrangling, you want the most raw data. It helps you get to know the data and makes the entire process reproducible. 

# Data Import

```{r setup, echo = FALSE, message = FALSE}
library(tidyverse)
library(readxl)
library(haven) 
```

We will be importing data within this document. Using R projects makes relative paths very easy. So as long as your data is in your project, its easy and doesn't require an absolute path. 

## Import the FAS Litters CSV

```{r litters import}
litters_df = read_csv("data_import_examples/FAS_litters.csv")

head(litters_df)
tail(litters_df, 15)
```

```{r eval = FALSE}
view(litters_df)
```


## Changing Column Names


```{r}
litters_df = janitor::clean_names(litters_df)
```

By default, clean names puts it into lower snake case across variables. The Janitor package is used to clean up a lot of data things. Since clean names is the only function that I need, I can use one line of code to say use this function from this package. 


# Learning Assessment

```{r import pups}
pups_df = read_csv("data_import_examples/FAS_pups.csv")
```

```{r}
head(pups_df, 15)
tail(pups_df, 15)
```

```{r}
pups_df = janitor::clean_names(pups_df)
```

```{r, echo=FALSE}
view(pups_df)
```


# Read CSV Options

Skip some rows and turn off column names: 

```{r}
litters_df = 
  read_csv(file = "data_import_examples/FAS_litters.csv", 
    col_names = FALSE, 
    skip = 1) 
```

What about missing data? 

```{r}
litters_df = 
  read_csv(
    file = "data_import_examples/FAS_litters.csv",
    na = c("NA", "", ".")
  )

```


```{r, echo=FALSE}
view(litters_df)
```

The code below will pull a variable from the dataset and call it something new if you want to do that (not necessary), then takes the mean of that variable. 

```{r}
litters_df = janitor::clean_names(litters_df) 

oweight= pull(litters_df, gd0_weight)
oweight

mean(oweight, na.rm = TRUE)
```

What if we code group as a factor variable? 

```{r}
litters_df = 
  read_csv(
    file = "data_import_examples/FAS_litters.csv", 
    na = c("NA","","."),
    col_types= cols(
      Group= col_factor()
    )
  )

```


# Excel Files

Importing MLB 2011 summary data. Sheet and range are specific to read_excel. 

```{r}
mlb_df = read_excel("data_import_examples/mlb11.xlsx", sheet = "mlb11")

mlb_df
```

```{r}
pulse_df = read_sas("data_import_examples/public_pulse_data.sas7bdat")

pulse_df
```





